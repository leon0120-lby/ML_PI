#1.1 Improntance

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
import numpy as np

#Read Excel file
file_path = r"E:\TG.xlsx" 
data = pd.read_excel(file_path)

X = data.iloc[:, :-1] 
y = data.iloc[:, -1] 

#Create a random forest regression model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# Obtain feature importance
importances = model.feature_importances_
feature_importance = pd.DataFrame({'finger': X.columns, 'importance': importances})
feature_importance = feature_importance.sort_values(by='importance', ascending=False)

# Select the first N features for display
top_n = 15  
top_features = feature_importance.head(top_n)

# Export filtered data to a new Excel file
# Obtain important feature names
selected_columns = top_features['finger'].tolist()

# Add tags and column names
label_column = data.columns[-1]
selected_columns.append(label_column)

# Create a new dataset containing important features and labels
selected_data = data[selected_columns]

# Save to a new Excel file
output_path = r"E:\TGresult.xlsx"
selected_data.to_excel(output_path, index=False)

import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap

base_colors = ["#FF6600", "#999999", "#5B9BD5"] 
cmap = LinearSegmentedColormap.from_list("gradient", base_colors, N=len(top_features))
palette = [cmap(i) for i in np.linspace(0, 1, len(top_features))]

plt.figure(figsize=(12, 10))
sns.barplot(
    x='importance', 
    y='finger', 
    data=top_features,
    palette=palette,         
    edgecolor='black',   
    linewidth=0.5,
    saturation=0.8          
)

plt.xlabel('Importance', fontsize=14)
plt.title('Top Feature Importance with Color Coding', fontsize=16)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12, rotation=0)

plt.text(
    0.95, 0.05, 
    "Color: Low → High Importance", 
    transform=plt.gca().transAxes,
    ha='right', va='bottom',
    fontsize=10,
    color='#666666'
)

plt.tight_layout()
plt.savefig(r"E:\TG\important.png", dpi=300, bbox_inches='tight')
plt.show()

#1.2boruta

import pandas as pd
import numpy as np
from boruta import BorutaPy
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

def load_data(file_path):

#Read Excel file
    df = pd.read_excel(file_path)
    features = df.iloc[:, :-1]  
    target = df.iloc[:, -1]    
    return features, target, df.columns[:-1]

def boruta_feature_selection(X, y, feature_names, n_estimators=100, min_features=15):
#Use Boruta algorithm for feature selection to ensure that at least min_features are retained
    rf = RandomForestRegressor(
        n_estimators=n_estimators, 
        max_depth=5,
        n_jobs=-1,
        random_state=42
    )
    
    boruta = BorutaPy(
        estimator=rf,
        n_estimators='auto',
        alpha=0.05,
        verbose=2,
        random_state=42,
        max_iter=100
    )
    
    boruta.fit(X.values, y.values)
    
    # Get filtering results
    selected = boruta.support_ 
    rankings = boruta.ranking_ 
    
    # Firstly, obtain the confirmed features from Boruta
    boruta_selected = selected.copy()
    
    # If the selected features are less than min_features, supplement the top ranked features
    if sum(boruta_selected) < min_features:
        
        # Obtain feature ranking (the smaller the value, the more important it is)
        sorted_indices = np.argsort(rankings)
        
        for i in range(min_features - sum(boruta_selected)):
            for idx in sorted_indices:
                if not boruta_selected[idx]:
                    boruta_selected[idx] = True
                    break
    result_df = pd.DataFrame({
        'Feature': feature_names,
        'Selected': boruta_selected, 
        'Ranking': rankings
    })
    
    result_df = result_df.sort_values('Ranking')
    
    return boruta, result_df

def plot_feature_ranking(result_df):
    #Draw a feature ranking map
    selected_df = result_df[result_df['Selected']].sort_values('Ranking')
    
    plt.figure(figsize=(10, 6))
    plt.barh(selected_df['Feature'], selected_df['Ranking'], color='skyblue')
    plt.xlabel('Boruta ranking (the smaller the value, the more important it is)')
    plt.title('Ranking of Boruta filtered features')
    plt.tight_layout()
    plt.savefig("E:\BROATO.png" , dpi=300, bbox_inches='tight')
    plt.show()

def save_results(original_df, boruta, result_df, output_file):
    selected_features = result_df[result_df['Selected']]['Feature'].tolist()
    new_df = original_df[selected_features + [original_df.columns[-1]]]
    
    new_df.to_excel(output_file, index=False)
    
    with pd.ExcelWriter(output_file, mode='a', engine='openpyxl') as writer:
        result_df.to_excel(writer, sheet_name='Boruta', index=False)
    
    return new_df

def main(input_file, output_file):
    features, target, feature_names = load_data(input_file)
    original_df = pd.concat([features, target], axis=1)
    
    boruta, result_df = boruta_feature_selection(features, target, feature_names, min_features=15)
    
    plot_feature_ranking(result_df)
    
    new_df = save_results(original_df, boruta, result_df, output_file)
    
    return new_df, result_df

if __name__ == "__main__":
    INPUT_EXCEL = r"E:\tg.xlsx"
    OUTPUT_EXCEL = r"E:\tgBORATO.xlsx"
    selected_data, report = main(INPUT_EXCEL, OUTPUT_EXCEL)

#1.3Mutual information regression

import pandas as pd
import numpy as np
from sklearn.feature_selection import mutual_info_regression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import time

def load_data(file_path):
    start_time = time.time()
    
    df = pd.read_excel(file_path)
    features = df.iloc[:, :-1]  
    target = df.iloc[:, -1] 
    
    return features, target, df

def calculate_mi_scores(X, y, random_state=42):
    start_time = time.time()
    
    np.random.seed(random_state)
    
    mi_scores = mutual_info_regression(
        X, 
        y,
        discrete_features='auto', 
        n_neighbors=5,           
        random_state=random_state
    )
    
    return mi_scores

def select_features(features, mi_scores, selection_method, k=None, threshold=None):

    mi_df = pd.DataFrame({
        'Feature': features.columns,
        'MI_Score': mi_scores
    }).sort_values('MI_Score', ascending=False)
    
    if selection_method == "top_k" and k is not None:
        selected_df = mi_df.head(k)
        
    elif selection_method == "percentile" and threshold is not None:

        score_threshold = np.percentile(mi_scores, threshold)
        selected_df = mi_df[mi_df['MI_Score'] >= score_threshold]
        print(f"≥{threshold}({score_threshold:.4f})")
        print(f"{len(selected_df)} ({len(selected_df)/len(mi_df)*100:.1f}%)")
    
    elif selection_method == "absolute_threshold" and threshold is not None:
        selected_df = mi_df[mi_df['MI_Score'] >= threshold]
    
    else:
        raise ValueError("erro")
    
    return selected_df

def visualize_results(mi_df, selected_features, n_show=30):

    plt.figure(figsize=(14, 10))
    
    colors = ['steelblue' if feat in selected_features else 'lightgray' 
              for feat in mi_df['Feature']]
    
    plt.barh(
        mi_df['Feature'][:n_show][::-1], 
        mi_df['MI_Score'][:n_show][::-1],
        color=colors[:n_show][::-1]
    )
    
    plt.title(f'Top {n_show} Feature mutual information score (blue represents selected features)', fontsize=14)
    plt.xlabel('Mutual information score', fontsize=12)
    plt.ylabel('Feature Name', fontsize=12)
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    

    plt.savefig("E:\imf.png" , dpi=300, bbox_inches='tight')
    plt.show()

def save_results(original_df, selected_features, output_file):

    feature_columns = selected_features['Feature'].tolist()
    new_df = original_df[feature_columns + [original_df.columns[-1]]]
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:

        new_df.to_excel(writer, sheet_name='sheet1', index=False)
        
        selected_features.to_excel(
            writer, 
            sheet_name='sheet2', 
            index=False
        )
    
def main():
    INPUT_FILE = r"E:\tg.xlsx"   
    OUTPUT_FILE = r"E:\tgimf.xlsx"   
    
    SELECTION_METHOD = "top_k"        
    
    TOP_K = 150                      
    PERCENTILE_THRESHOLD = 90          
    ABSOLUTE_THRESHOLD = 0.05       

    features, target, original_df = load_data(INPUT_FILE)
    
    mi_scores = calculate_mi_scores(features, target)
    
    selected_features = select_features(
        features, 
        mi_scores,
        selection_method=SELECTION_METHOD,
        k=TOP_K,
        threshold=PERCENTILE_THRESHOLD if SELECTION_METHOD == "percentile" else ABSOLUTE_THRESHOLD
    )
    
    visualize_results(
        pd.DataFrame({
            'Feature': features.columns,
            'MI_Score': mi_scores
        }).sort_values('MI_Score', ascending=False),
        selected_features['Feature'].tolist()
    )
    
    save_results(original_df, selected_features, OUTPUT_FILE)
    
    for i, row in selected_features.head().iterrows():
        print(f"- {row['Feature']}: {row['MI_Score']:.4f}")

if __name__ == "__main__":
    main()

#1.4LASSO
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
import joblib 
import time
import os

def load_data(file_path):
    start_time = time.time()

    df = pd.read_excel(file_path, dtype=np.float32)
    

    features = df.iloc[:, :-1]
    target = df.iloc[:, -1]   
    
    return features.values, target.values, df, features.columns

def accelerated_lasso(X, y, alphas=None, cv=3, n_jobs=-1):

    start_time = time.time()
    
    if alphas is None:
        alphas = np.logspace(-4, 0, 30)
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    model = LassoCV(
        alphas=alphas,
        cv=cv,          
        max_iter=1000,  
        tol=1e-3,      
        n_jobs=n_jobs, 
        precompute=True, 
        selection='random', 
        random_state=42
    )
    
    model.fit(X_scaled, y)
    
    results = {
        'best_alpha': model.alpha_,
        'coef': model.coef_,
        'mse_path': model.mse_path_,
        'alphas': model.alphas_,
        'n_iter': model.n_iter_
    }
       
    return model, results

def visualize_and_save(lasso_model, feature_names, original_df):

    non_zero_idx = np.where(lasso_model.coef_ != 0)[0]
    non_zero_coef = lasso_model.coef_[non_zero_idx]
    non_zero_features = [feature_names[i] for i in non_zero_idx]
    
    coef_df = pd.DataFrame({
        'Feature': non_zero_features,
        'Coefficient': non_zero_coef,
        'Abs_Coefficient': np.abs(non_zero_coef)
    }).sort_values('Abs_Coefficient', ascending=False)
    
    plt.figure(figsize=(10, 8))
    plt.barh(coef_df['Feature'].head(20)[::-1], 
             coef_df['Abs_Coefficient'].head(20)[::-1],
             color=['green' if c > 0 else 'red' for c in coef_df['Coefficient'].head(20)[::-1]])
    plt.title('Top 20 features')
    plt.xlabel('Absolute value of coefficient')
    plt.tight_layout()
    
    output_file = r"E:\tg.xlsx"
    selected_df = original_df[non_zero_features + [original_df.columns[-1]]]
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        selected_df.to_excel(writer, sheet_name='sheet1', index=False)
        coef_df.to_excel(writer, sheet_name='sheet2', index=False)
    
    return coef_df

def main():
    INPUT_FILE = r"E:\tg.xlsx"
    
    n_cores = joblib.cpu_count()
    
    X, y, original_df, feature_names = load_data(INPUT_FILE)
    
    start_time = time.time()
    lasso_model, results = accelerated_lasso(X, y)
    total_time = time.time() - start_time

    coef_df = visualize_and_save(lasso_model, feature_names, original_df)

    for i, row in coef_df.head(3).iterrows():
        effect = "add" if row['Coefficient'] > 0 else "decline"
        print(f"   - {row['Feature']}: {abs(row['Coefficient']):.4f} ({effect})")

if __name__ == "__main__":
    main()
